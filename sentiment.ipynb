{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv, sys, re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv('dataset.tsv', sep='\\t', quoting=csv.QUOTE_NONE , dtype= str, header = None, names=[\"instance\", \"text\", \"id\", \"sentiment\",\"is_sarcastic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = np.array([])\n",
    "for text in df.text:\n",
    "    text_data = np.append(text_data,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \"\", sample)\n",
    "\n",
    "\n",
    "def remove_punctuation(sample):\n",
    "    \"\"\"Remove punctuations from a sample string\"\"\"\n",
    "    punctuations = '''!\"&'()*+,-./:;<=>?[\\]^`{|}~'''\n",
    "    no_punct = \"\"\n",
    "    for char in sample:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "\n",
    "def myPreprocessor(sample):\n",
    "    \"\"\"Customized preprocessor\"\"\"\n",
    "    sample = remove_URL(sample)\n",
    "    sample = remove_punctuation(sample)\n",
    "    return sample\n",
    "\n",
    "\n",
    "def myTokenizer(sample):\n",
    "    \"\"\"Customized tokenizer\"\"\"\n",
    "    new_words = []\n",
    "    words = sample.split(' ')\n",
    "    new_words = [word for word in words if len(word) >= 2]\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#AFPRaids', '#AusPol', '#AusVotes', '#Auspol', '#Ausvotes', '#Brexit', '#Election2016', '#LNP', '#LNPfail', '#Labor', '#Medicare', '#NBN', '#Parakeelia', '#auspol', '#ausvotes', '#ausvotes2016', '#insiders', '#npc', '#qanda', '@AustralianLabor', '@LiberalAus', '@RichardDiNatale', '@TurnbullMalcolm', '@billshortenmp', 'AFP', 'ALP', 'Abbott', 'Australia', 'Australian', 'Australians', 'Bill', 'Coalition', 'Dutton', 'Government', 'Govt', 'Greens', 'How', 'If', 'Its', 'Joyce', 'LNP', 'Labor', 'Labors', 'Liberal', 'Liberals', 'Libs', 'Malcolm', 'Medicare', 'Morrison', 'NBN', 'No', 'Not', 'PM', 'Party', 'Peter', 'Shorten', 'So', 'THE', 'The', 'This', 'Turnbull', 'Turnbulls', 'VOTE', 'Vote', 'We', 'What', 'Why', 'You', 'about', 'after', 'again', 'all', 'amp', 'an', 'and', 'any', 'are', 'as', 'at', 'back', 'be', 'because', 'been', 'big', 'boats', 'budget', 'business', 'but', 'by', 'campaign', 'can', 'cant', 'care', 'could', 'cut', 'cuts', 'did', 'do', 'dont', 'down', 'economic', 'economy', 'education', 'election', 'even', 'for', 'from', 'funding', 'gearing', 'get', 'going', 'good', 'government', 'govt', 'growth', 'had', 'has', 'have', 'he', 'health', 'his', 'how', 'if', 'in', 'into', 'is', 'it', 'its', 'jobs', 'just', 'know', 'labor', 'last', 'like', 'money', 'more', 'must', 'need', 'no', 'not', 'now', 'of', 'on', 'one', 'only', 'or', 'our', 'out', 'over', 'own', 'party', 'pay', 'people', 'plan', 'plans', 'plebiscite', 'policy', 'put', 'refugees', 'right', 'say', 'says', 'schools', 'so', 'support', 'take', 'tax', 'taxes', 'than', 'that', 'the', 'their', 'them', 'there', 'they', 'think', 'this', 'time', 'to', 'under', 'up', 'us', 'via', 'vote', 'want', 'wants', 'was', 'we', 'what', 'when', 'who', 'why', 'will', 'with', 'wont', 'work', 'workers', 'would', 'you', 'your']\n",
      "{'@LiberalAus': 20, 'health': 119, 'is': 125, 'tax': 166, 'Its': 38, 'all': 71, 'and': 74, '#auspol': 13, 'Labor': 41, 'amp': 72, 'the': 170, 'Greens': 35, 'dont': 98, 'support': 164, 'campaign': 89, 'of': 141, 'by': 88, 'plebiscite': 155, 'on': 142, 'there': 173, 'no': 138, 'was': 186, 'Turnbull': 60, 'he': 118, 'an': 73, 'again': 70, '@TurnbullMalcolm': 22, 'Shorten': 55, 'are': 76, 'not': 139, 'for': 105, 'or': 145, '#ausvotes': 14, 'Turnbulls': 61, 'jobs': 128, 'plan': 153, 'even': 104, 'up': 180, 'to': 178, 'in': 123, 'says': 161, 'Labors': 42, 'NBN': 49, 'policy': 156, 'funding': 107, '#LNP': 7, '#qanda': 18, 'time': 177, 'you': 198, '@AustralianLabor': 19, 'our': 146, 'as': 77, 'cut': 94, 'Govt': 34, 'down': 99, '#AusVotes': 2, '#AusPol': 1, 'LNP': 40, 'last': 132, 'So': 56, 'Morrison': 48, 'will': 192, 'get': 109, 'from': 106, '@billshortenmp': 23, 'How': 36, 'money': 134, '#Parakeelia': 12, 'workers': 196, '#NBN': 11, 'has': 116, 'been': 82, 'its': 127, 'could': 93, 'why': 191, 'after': 69, 'Coalition': 31, 'boats': 84, 'be': 80, 'this': 176, 'VOTE': 62, 'Libs': 45, 'say': 160, 'people': 152, 'their': 171, 'Bill': 30, '#Brexit': 5, 'vote': 183, 'need': 137, 'growth': 114, 'want': 184, 'schools': 162, 'cuts': 95, 'at': 78, 'What': 65, 'going': 110, 'over': 148, '#insiders': 16, 'with': 193, 'his': 120, 'own': 149, 'wants': 185, 'it': 126, 'Australia': 27, 'like': 133, 'budget': 85, 'do': 97, 'know': 130, 'about': 68, 'economic': 100, 'how': 121, 'PM': 52, 'taxes': 167, 'must': 136, 'We': 64, 'cant': 91, 'they': 174, '#ausvotes2016': 15, 'The': 58, 'Australians': 29, 'we': 187, 'one': 143, 'more': 135, 'than': 168, 'Malcolm': 46, 'but': 87, 'that': 169, 'refugees': 158, 'back': 79, 'good': 111, 'If': 37, 'can': 90, '#LNPfail': 8, 'Liberals': 44, 'into': 124, 'out': 147, '#npc': 17, 'wont': 194, 'pay': 151, '#Labor': 9, 'because': 81, 'via': 182, '#Auspol': 3, '@RichardDiNatale': 21, 'govt': 113, 'when': 189, '#Election2016': 6, 'care': 92, 'have': 117, 'Liberal': 43, '#Medicare': 10, 'Party': 53, 'This': 59, 'what': 188, 'just': 129, 'Dutton': 32, 'would': 197, 'work': 195, 'did': 96, 'education': 102, 'under': 179, 'business': 86, 'Not': 51, 'economy': 101, 'think': 175, 'if': 122, 'party': 150, 'Government': 33, 'gearing': 108, '#AFPRaids': 0, 'ALP': 25, 'them': 172, 'now': 140, 'Joyce': 39, 'any': 75, 'so': 163, 'No': 50, 'only': 144, 'Why': 66, 'who': 190, 'Australian': 28, 'government': 112, 'take': 165, 'right': 159, 'Abbott': 26, 'put': 157, '#Ausvotes': 4, 'us': 181, 'had': 115, 'labor': 131, 'Peter': 54, 'You': 67, 'AFP': 24, 'your': 199, 'plans': 154, 'Medicare': 47, 'THE': 57, 'election': 103, 'big': 83, 'Vote': 63}\n"
     ]
    }
   ],
   "source": [
    "count = CountVectorizer(preprocessor=myPreprocessor, lowercase = False, tokenizer=myTokenizer ,max_features = 200)\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "print(count.get_feature_names())\n",
    "print(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target classes\n",
    "Y = np.array([])\n",
    "for text in df.sentiment:\n",
    "    Y = np.append(Y,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:1500]\n",
    "X_test = X[1500:]\n",
    "y_train = Y[:1500]\n",
    "y_test = Y[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = MultinomialNB()\n",
    "#clf = BernoulliNB()\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy',random_state=0) \n",
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.656\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'negative' 'negative' 'negative' 'neutral' 'negative'\n",
      " 'negative' 'neutral' 'negative' 'positive' 'neutral' 'neutral' 'negative'\n",
      " 'negative' 'positive' 'neutral' 'neutral' 'negative' 'negative'\n",
      " 'positive' 'negative' 'neutral' 'neutral' 'negative' 'negative'\n",
      " 'negative' 'positive' 'negative' 'negative' 'neutral' 'negative'\n",
      " 'negative' 'negative' 'positive' 'neutral' 'negative' 'negative'\n",
      " 'negative' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'neutral' 'neutral' 'neutral' 'neutral' 'negative'\n",
      " 'neutral' 'negative' 'positive' 'neutral' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'neutral'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'negative' 'neutral'\n",
      " 'positive' 'neutral' 'neutral' 'negative' 'positive' 'negative'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'negative' 'positive'\n",
      " 'neutral' 'negative' 'negative' 'positive' 'negative' 'neutral' 'neutral'\n",
      " 'positive' 'neutral' 'negative' 'neutral' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'neutral' 'negative' 'neutral' 'negative' 'negative'\n",
      " 'positive' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'negative' 'neutral' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'neutral' 'negative' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'neutral' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
      " 'negative' 'neutral' 'negative' 'negative' 'neutral' 'negative'\n",
      " 'positive' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'negative' 'neutral' 'neutral' 'negative' 'positive'\n",
      " 'neutral' 'negative' 'neutral' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'neutral' 'positive' 'neutral' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'positive' 'negative' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'negative' 'neutral' 'negative'\n",
      " 'negative' 'positive' 'neutral' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'neutral' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'positive' 'neutral' 'neutral' 'neutral' 'neutral'\n",
      " 'positive' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'negative' 'positive'\n",
      " 'negative' 'negative' 'neutral' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'neutral' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'neutral' 'negative' 'negative' 'positive'\n",
      " 'negative' 'neutral' 'neutral' 'negative' 'neutral' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'neutral' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'neutral' 'negative' 'negative' 'neutral' 'neutral' 'negative'\n",
      " 'neutral' 'neutral' 'negative' 'negative' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'negative' 'positive' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'neutral' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'neutral' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'negative' 'neutral' 'neutral' 'neutral' 'negative'\n",
      " 'negative' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'negative' 'neutral' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'neutral' 'negative' 'neutral' 'negative' 'neutral' 'neutral'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'neutral' 'negative' 'neutral'\n",
      " 'negative' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'neutral' 'neutral' 'neutral'\n",
      " 'neutral' 'negative' 'neutral' 'negative' 'negative' 'neutral' 'neutral'\n",
      " 'negative' 'neutral' 'neutral' 'neutral' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'neutral' 'neutral' 'neutral' 'negative' 'negative' 'positive'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'neutral' 'negative'\n",
      " 'positive' 'positive' 'neutral' 'negative' 'negative' 'negative'\n",
      " 'negative' 'neutral' 'neutral' 'negative' 'neutral' 'negative' 'negative'\n",
      " 'negative' 'neutral' 'neutral' 'neutral' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'positive' 'negative' 'neutral' 'negative'\n",
      " 'neutral' 'neutral' 'negative' 'neutral' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'neutral'] ['negative' 'neutral' 'negative' 'negative' 'neutral' 'negative' 'neutral'\n",
      " 'positive' 'negative' 'neutral' 'neutral' 'negative' 'negative'\n",
      " 'negative' 'negative' 'neutral' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'negative' 'negative'\n",
      " 'neutral' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'neutral' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'negative' 'neutral' 'negative'\n",
      " 'negative' 'negative' 'neutral' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'neutral' 'positive'\n",
      " 'negative' 'neutral' 'negative' 'positive' 'neutral' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'neutral'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'positive'\n",
      " 'neutral' 'negative' 'negative' 'neutral' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'neutral' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'negative' 'neutral'\n",
      " 'positive' 'negative' 'neutral' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'neutral' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'neutral' 'neutral' 'neutral' 'negative' 'neutral' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'neutral'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'negative' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'neutral' 'negative'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'neutral' 'neutral' 'negative'\n",
      " 'neutral' 'neutral' 'positive' 'negative' 'negative' 'neutral' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'neutral' 'neutral' 'neutral' 'negative' 'neutral' 'positive' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'neutral' 'negative' 'neutral' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'negative' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'positive' 'neutral' 'negative'\n",
      " 'negative' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'neutral'\n",
      " 'neutral' 'positive' 'positive' 'neutral' 'neutral' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'neutral' 'neutral'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'neutral' 'neutral' 'neutral'\n",
      " 'neutral' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'positive'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'neutral' 'neutral' 'neutral'\n",
      " 'neutral' 'neutral' 'positive' 'negative' 'neutral' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'neutral'\n",
      " 'neutral' 'negative' 'negative' 'positive' 'negative' 'neutral' 'neutral'\n",
      " 'negative' 'negative' 'neutral' 'neutral' 'neutral' 'negative' 'negative'\n",
      " 'negative' 'negative' 'neutral' 'neutral' 'negative' 'positive'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'neutral' 'negative'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'negative' 'negative'\n",
      " 'positive' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'negative' 'neutral' 'neutral' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'neutral' 'negative'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'negative'\n",
      " 'negative' 'neutral' 'negative' 'negative' 'neutral' 'neutral' 'negative'\n",
      " 'negative' 'negative' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'neutral' 'positive' 'negative' 'negative'\n",
      " 'negative' 'neutral' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'negative' 'negative' 'neutral' 'positive' 'negative'\n",
      " 'neutral' 'negative' 'negative' 'positive' 'neutral' 'neutral' 'negative'\n",
      " 'neutral' 'neutral' 'negative' 'neutral' 'neutral' 'negative' 'negative'\n",
      " 'negative' 'positive' 'neutral' 'neutral' 'negative' 'negative' 'neutral'\n",
      " 'negative' 'neutral' 'neutral' 'negative' 'negative' 'negative'\n",
      " 'positive' 'neutral' 'neutral' 'neutral' 'negative' 'neutral' 'negative'\n",
      " 'negative' 'negative' 'neutral' 'negative' 'neutral' 'negative' 'neutral'\n",
      " 'negative' 'neutral' 'neutral' 'negative' 'negative' 'neutral' 'negative'\n",
      " 'negative' 'negative' 'neutral' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'neutral' 'negative' 'neutral' 'negative' 'neutral'\n",
      " 'neutral' 'neutral' 'negative' 'negative' 'neutral' 'negative' 'negative'\n",
      " 'neutral' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'neutral' 'negative' 'positive' 'neutral' 'negative'\n",
      " 'negative' 'neutral' 'negative' 'neutral' 'negative' 'negative'\n",
      " 'negative' 'neutral' 'neutral' 'neutral' 'negative' 'neutral' 'negative'\n",
      " 'negative' 'negative' 'negative' 'neutral' 'positive' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'neutral' 'neutral'\n",
      " 'negative' 'neutral' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'neutral']\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "0.656\n",
      "0.656\n",
      "0.656\n",
      "0.656\n",
      "0.5096653087307293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.76      0.77       326\n",
      "     neutral       0.49      0.51      0.50       137\n",
      "    positive       0.24      0.27      0.26        37\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       500\n",
      "   macro avg       0.51      0.51      0.51       500\n",
      "weighted avg       0.66      0.66      0.66       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y_test, predicted_y)\n",
    "print(model.predict_proba(X_test))\n",
    "print(accuracy_score(y_test, predicted_y))\n",
    "print(precision_score(y_test, predicted_y, average='micro'))\n",
    "print(recall_score(y_test, predicted_y, average='micro'))\n",
    "print(f1_score(y_test, predicted_y, average='micro', labels = np.unique(predicted_y)))\n",
    "print(f1_score(y_test, predicted_y, average='macro', labels = np.unique(predicted_y)))\n",
    "print(classification_report(y_test, predicted_y,output_dict= False, labels = np.unique(predicted_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
