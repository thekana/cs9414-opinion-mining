{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv, sys, re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv('dataset.tsv', sep='\\t', quoting=csv.QUOTE_NONE , dtype= str, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>1715</td>\n",
       "      <td>The Libs complaining about a Medicare scare ca...</td>\n",
       "      <td>10005</td>\n",
       "      <td>negative</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>1609</td>\n",
       "      <td>Labor message to Asylum Seekers 'Come on in' #...</td>\n",
       "      <td>10008</td>\n",
       "      <td>neutral</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>1624</td>\n",
       "      <td>@Greens @RichardDiNatale the economy of Tasman...</td>\n",
       "      <td>10003</td>\n",
       "      <td>negative</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1      2  \\\n",
       "1714  1715  The Libs complaining about a Medicare scare ca...  10005   \n",
       "1608  1609  Labor message to Asylum Seekers 'Come on in' #...  10008   \n",
       "1623  1624  @Greens @RichardDiNatale the economy of Tasman...  10003   \n",
       "\n",
       "             3      4  \n",
       "1714  negative  false  \n",
       "1608   neutral  false  \n",
       "1623  negative  false  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=shuffle(df)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in df[1]:\n",
    "    text_data = np.append(text_data,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \"\", sample)\n",
    "\n",
    "\n",
    "def remove_punctuation(sample):\n",
    "    \"\"\"Remove punctuations from a sample string\"\"\"\n",
    "    punctuations = '''!\"&'()*+,-./:;<=>?[\\]^`{|}~'''\n",
    "    no_punct = \"\"\n",
    "    for char in sample:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "\n",
    "def myPreprocessor(sample):\n",
    "    \"\"\"Customized preprocessor\"\"\"\n",
    "    sample = remove_URL(sample)\n",
    "    sample = remove_punctuation(sample)\n",
    "    return sample\n",
    "\n",
    "\n",
    "def myTokenizer(sample):\n",
    "    \"\"\"Customized tokenizer\"\"\"\n",
    "    new_words = []\n",
    "    words = sample.split(' ')\n",
    "    new_words = [word for word in words if len(word) >= 2]\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#AFPRaids', '#AusPol', '#AusVotes', '#Auspol', '#Ausvotes', '#Brexit', '#Election2016', '#LNP', '#LNPfail', '#Labor', '#Medicare', '#NBN', '#Parakeelia', '#auspol', '#ausvotes', '#ausvotes2016', '#insiders', '#npc', '#qanda', '@AustralianLabor', '@LiberalAus', '@RichardDiNatale', '@TurnbullMalcolm', '@billshortenmp', 'AFP', 'ALP', 'Abbott', 'Australia', 'Australian', 'Australians', 'Bill', 'Coalition', 'Dutton', 'Government', 'Govt', 'Greens', 'How', 'If', 'Its', 'Joyce', 'LNP', 'Labor', 'Labors', 'Liberal', 'Liberals', 'Libs', 'Malcolm', 'Medicare', 'Morrison', 'NBN', 'No', 'Not', 'PM', 'Party', 'Peter', 'Shorten', 'So', 'THE', 'The', 'This', 'Turnbull', 'Turnbulls', 'VOTE', 'Vote', 'We', 'What', 'Why', 'You', 'about', 'after', 'again', 'all', 'amp', 'an', 'and', 'any', 'are', 'as', 'at', 'back', 'be', 'because', 'been', 'big', 'boats', 'budget', 'business', 'but', 'by', 'campaign', 'can', 'cant', 'care', 'could', 'cut', 'cuts', 'did', 'do', 'dont', 'down', 'economic', 'economy', 'education', 'election', 'even', 'for', 'from', 'funding', 'gearing', 'get', 'going', 'good', 'government', 'govt', 'growth', 'had', 'has', 'have', 'he', 'health', 'his', 'how', 'if', 'in', 'into', 'is', 'it', 'its', 'jobs', 'just', 'know', 'labor', 'last', 'like', 'money', 'more', 'must', 'need', 'no', 'not', 'now', 'of', 'on', 'one', 'only', 'or', 'our', 'out', 'over', 'own', 'party', 'pay', 'people', 'plan', 'plans', 'plebiscite', 'policy', 'put', 'refugees', 'right', 'say', 'says', 'schools', 'so', 'support', 'take', 'tax', 'taxes', 'than', 'that', 'the', 'their', 'them', 'there', 'they', 'think', 'this', 'time', 'to', 'under', 'up', 'us', 'via', 'vote', 'want', 'wants', 'was', 'we', 'what', 'when', 'who', 'why', 'will', 'with', 'wont', 'work', 'workers', 'would', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "count = CountVectorizer(preprocessor=myPreprocessor, lowercase = True, tokenizer=myTokenizer ,max_features = 200)\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "print(count.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 58, 'Libs': 45, 'about': 68, 'Medicare': 47, 'campaign': 89, 'is': 125, 'like': 133, 'Turnbull': 60, '#ausvotes': 14, 'Labor': 41, 'to': 178, 'on': 142, 'in': 123, '#auspol': 13, '@RichardDiNatale': 21, 'the': 170, 'economy': 101, 'of': 141, 'what': 188, 'when': 189, 'have': 117, 'THE': 57, 'VOTE': 62, 'LNP': 40, 'up': 180, 'how': 121, 'boats': 84, 'why': 191, 'Abbott': 26, 'was': 186, 'by': 88, 'says': 161, 'and': 74, 'with': 193, 'economic': 100, '#npc': 17, 'Joyce': 39, 'support': 164, 'for': 105, 'any': 75, '#Auspol': 3, 'its': 127, 'will': 192, 'it': 126, 'people': 152, 'his': 120, 'need': 137, 'put': 157, 'last': 132, 'Liberals': 44, 'from': 106, 'after': 69, 'amp': 72, '@LiberalAus': 20, 'plans': 154, 'do': 97, 'you': 198, 'our': 146, 'Australians': 29, 'want': 184, 'an': 73, 'You': 67, 'cant': 91, '#Election2016': 6, 'vote': 183, 'their': 171, 'Greens': 35, 'dont': 98, 'Malcolm': 46, 'plebiscite': 155, 'this': 176, 'What': 65, 'cut': 94, 'via': 182, 'out': 147, 'budget': 85, 'them': 172, 'been': 82, 'Party': 53, 'Australia': 27, '#LNP': 7, 'be': 80, 'Australian': 28, 'taxes': 167, 'time': 177, 'Peter': 54, 'workers': 196, 'jobs': 128, '#LNPfail': 8, '#Ausvotes': 4, '@AustralianLabor': 19, 'Not': 51, 'back': 79, 'Shorten': 55, 'wont': 194, 'over': 148, '@TurnbullMalcolm': 22, 'more': 135, 'govt': 113, 'No': 50, 'or': 145, 'under': 179, 'policy': 156, 'take': 165, 'are': 76, 'refugees': 158, 'Bill': 30, '#Parakeelia': 12, 'party': 150, 'that': 169, 'than': 168, 'one': 143, 'Turnbulls': 61, '#NBN': 11, 'This': 59, 'government': 112, 'but': 87, 'who': 190, 'schools': 162, 'Liberal': 43, 'at': 78, 'Morrison': 48, 'ALP': 25, 'now': 140, 'there': 173, 'going': 110, 'know': 130, '@billshortenmp': 23, 'Coalition': 31, 'just': 129, 'not': 139, 'cuts': 95, 'so': 163, 'us': 181, 'AFP': 24, 'own': 149, '#AusVotes': 2, 'NBN': 49, '#Labor': 9, 'has': 116, 'tax': 166, 'as': 77, 'health': 119, 'education': 102, 'because': 81, 'would': 197, 'no': 138, 'growth': 114, 'they': 174, 'we': 187, 'your': 199, 'Dutton': 32, 'wants': 185, '#AFPRaids': 0, '#qanda': 18, 'Labors': 42, 'Government': 33, '#ausvotes2016': 15, 'all': 71, 'had': 115, 'get': 109, '#Medicare': 10, 'If': 37, 'say': 160, 'could': 93, 'plan': 153, 'care': 92, 'think': 175, 'How': 36, 'into': 124, 'if': 122, 'he': 118, 'good': 111, 'PM': 52, 'only': 144, 'can': 90, 'Why': 66, 'business': 86, 'big': 83, '#insiders': 16, 'Govt': 34, 'funding': 107, 'Its': 38, 'down': 99, 'Vote': 63, 'work': 195, 'labor': 131, 'right': 159, 'pay': 151, 'election': 103, 'money': 134, 'must': 136, '#AusPol': 1, 'We': 64, 'gearing': 108, '#Brexit': 5, 'did': 96, 'again': 70, 'So': 56, 'even': 104}\n"
     ]
    }
   ],
   "source": [
    "print(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target classes\n",
    "Y = np.array([])\n",
    "for text in df[2]:\n",
    "    Y = np.append(Y,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:1500]\n",
    "X_test = X[1500:]\n",
    "y_train = Y[:1500]\n",
    "y_test = Y[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = MultinomialNB()\n",
    "#clf = BernoulliNB()\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy',random_state=0) \n",
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.236\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10008' '10018' '10013' '10005' '10002' '10007' '10014' '10000' '10009'\n",
      " '10011' '10013' '10015' '10008' '10002' '10002' '10016' '10002' '10019'\n",
      " '10010' '10015' '10008' '10005' '10006' '10006' '10005' '10013' '10005'\n",
      " '10005' '10000' '10016' '10000' '10000' '10005' '10005' '10003' '10008'\n",
      " '10006' '10007' '10005' '10003' '10003' '10006' '10003' '10000' '10000'\n",
      " '10003' '10004' '10016' '10003' '10003' '10002' '10015' '10013' '10008'\n",
      " '10000' '10001' '10006' '10000' '10012' '10006' '10001' '10003' '10008'\n",
      " '10008' '10008' '10004' '10005' '10015' '10015' '10003' '10003' '10006'\n",
      " '10000' '10014' '10003' '10003' '10003' '10000' '10014' '10005' '10008'\n",
      " '10008' '10013' '10002' '10002' '10003' '10000' '10013' '10006' '10000'\n",
      " '10006' '10005' '10000' '10000' '10006' '10003' '10000' '10001' '10003'\n",
      " '10000' '10001' '10009' '10003' '10016' '10000' '10008' '10015' '10006'\n",
      " '10001' '10003' '10008' '10005' '10000' '10000' '10006' '10000' '10010'\n",
      " '10006' '10000' '10001' '10008' '10015' '10001' '10019' '10003' '10000'\n",
      " '10005' '10008' '10006' '10005' '10003' '10000' '10000' '10003' '10003'\n",
      " '10006' '10012' '10001' '10003' '10001' '10017' '10009' '10013' '10008'\n",
      " '10001' '10016' '10012' '10015' '10001' '10005' '10000' '10008' '10000'\n",
      " '10003' '10008' '10017' '10005' '10003' '10000' '10006' '10000' '10016'\n",
      " '10001' '10005' '10000' '10019' '10006' '10000' '10005' '10013' '10019'\n",
      " '10008' '10009' '10018' '10000' '10003' '10006' '10008' '10019' '10015'\n",
      " '10017' '10002' '10003' '10003' '10005' '10019' '10019' '10013' '10003'\n",
      " '10006' '10013' '10013' '10002' '10008' '10013' '10016' '10010' '10015'\n",
      " '10011' '10008' '10005' '10003' '10017' '10005' '10001' '10014' '10016'\n",
      " '10017' '10005' '10005' '10000' '10003' '10000' '10005' '10006' '10006'\n",
      " '10005' '10018' '10017' '10003' '10002' '10015' '10002' '10003' '10000'\n",
      " '10019' '10003' '10010' '10003' '10006' '10006' '10003' '10000' '10003'\n",
      " '10003' '10010' '10005' '10010' '10000' '10003' '10003' '10008' '10000'\n",
      " '10017' '10008' '10019' '10018' '10003' '10003' '10000' '10008' '10003'\n",
      " '10006' '10002' '10000' '10006' '10001' '10006' '10002' '10003' '10008'\n",
      " '10018' '10010' '10001' '10015' '10010' '10002' '10005' '10005' '10013'\n",
      " '10015' '10005' '10005' '10001' '10013' '10013' '10004' '10003' '10017'\n",
      " '10012' '10002' '10003' '10015' '10008' '10016' '10004' '10010' '10016'\n",
      " '10001' '10013' '10008' '10003' '10006' '10005' '10008' '10005' '10003'\n",
      " '10003' '10005' '10017' '10018' '10015' '10003' '10003' '10019' '10003'\n",
      " '10001' '10005' '10015' '10019' '10003' '10003' '10013' '10003' '10002'\n",
      " '10013' '10019' '10005' '10008' '10017' '10015' '10008' '10003' '10015'\n",
      " '10013' '10010' '10019' '10006' '10001' '10003' '10001' '10005' '10005'\n",
      " '10006' '10010' '10016' '10008' '10005' '10003' '10008' '10009' '10000'\n",
      " '10000' '10005' '10000' '10000' '10000' '10008' '10003' '10003' '10008'\n",
      " '10002' '10001' '10002' '10003' '10018' '10019' '10012' '10014' '10003'\n",
      " '10000' '10015' '10005' '10006' '10006' '10001' '10001' '10000' '10015'\n",
      " '10005' '10003' '10003' '10016' '10013' '10016' '10008' '10006' '10015'\n",
      " '10006' '10003' '10017' '10000' '10005' '10014' '10003' '10006' '10000'\n",
      " '10006' '10005' '10000' '10003' '10008' '10001' '10008' '10005' '10002'\n",
      " '10002' '10008' '10003' '10005' '10015' '10015' '10003' '10006' '10000'\n",
      " '10010' '10010' '10003' '10005' '10013' '10006' '10013' '10000' '10000'\n",
      " '10000' '10005' '10005' '10015' '10000' '10003' '10002' '10013' '10009'\n",
      " '10004' '10000' '10003' '10001' '10006' '10003' '10015' '10006' '10000'\n",
      " '10000' '10013' '10011' '10008' '10003' '10002' '10006' '10005' '10005'\n",
      " '10003' '10012' '10000' '10005' '10002' '10006' '10013' '10006' '10003'\n",
      " '10006' '10015' '10005' '10016' '10005' '10017' '10006' '10001' '10005'\n",
      " '10003' '10002' '10010' '10003' '10005' '10013' '10013' '10013' '10001'\n",
      " '10006' '10005' '10000' '10006' '10005' '10006' '10003' '10008' '10003'\n",
      " '10001' '10008' '10003' '10003' '10018' '10001' '10003' '10000' '10000'\n",
      " '10000' '10005' '10001' '10002' '10006' '10006' '10014' '10006' '10006'\n",
      " '10000' '10003' '10002' '10002' '10006'] ['10000' '10006' '10003' '10003' '10003' '10003' '10003' '10003' '10003'\n",
      " '10000' '10003' '10003' '10018' '10003' '10003' '10003' '10001' '10003'\n",
      " '10003' '10003' '10008' '10003' '10003' '10000' '10003' '10003' '10003'\n",
      " '10010' '10000' '10006' '10000' '10003' '10003' '10003' '10003' '10008'\n",
      " '10006' '10003' '10003' '10003' '10003' '10006' '10003' '10000' '10003'\n",
      " '10003' '10003' '10015' '10003' '10003' '10003' '10003' '10013' '10008'\n",
      " '10000' '10003' '10003' '10000' '10013' '10003' '10002' '10003' '10003'\n",
      " '10003' '10003' '10003' '10005' '10015' '10015' '10003' '10003' '10003'\n",
      " '10003' '10001' '10002' '10003' '10003' '10000' '10003' '10003' '10008'\n",
      " '10003' '10003' '10002' '10003' '10003' '10000' '10003' '10003' '10000'\n",
      " '10008' '10003' '10003' '10003' '10003' '10002' '10000' '10008' '10000'\n",
      " '10000' '10003' '10003' '10003' '10008' '10015' '10008' '10000' '10003'\n",
      " '10003' '10008' '10003' '10005' '10000' '10000' '10003' '10000' '10005'\n",
      " '10006' '10003' '10008' '10008' '10015' '10000' '10003' '10003' '10000'\n",
      " '10003' '10008' '10003' '10005' '10003' '10003' '10005' '10003' '10003'\n",
      " '10002' '10003' '10000' '10003' '10003' '10016' '10003' '10003' '10008'\n",
      " '10003' '10008' '10001' '10003' '10003' '10005' '10000' '10008' '10000'\n",
      " '10001' '10000' '10005' '10005' '10003' '10000' '10003' '10000' '10000'\n",
      " '10003' '10003' '10000' '10008' '10003' '10003' '10005' '10003' '10003'\n",
      " '10015' '10003' '10003' '10005' '10003' '10000' '10003' '10013' '10003'\n",
      " '10003' '10002' '10003' '10003' '10006' '10003' '10013' '10005' '10005'\n",
      " '10006' '10003' '10013' '10013' '10008' '10003' '10003' '10005' '10003'\n",
      " '10003' '10008' '10003' '10003' '10008' '10003' '10003' '10003' '10008'\n",
      " '10008' '10003' '10005' '10003' '10005' '10000' '10003' '10003' '10003'\n",
      " '10003' '10018' '10008' '10003' '10003' '10000' '10003' '10003' '10000'\n",
      " '10003' '10003' '10002' '10005' '10001' '10003' '10003' '10003' '10003'\n",
      " '10003' '10003' '10003' '10003' '10016' '10017' '10003' '10003' '10003'\n",
      " '10003' '10006' '10003' '10000' '10003' '10001' '10000' '10006' '10003'\n",
      " '10006' '10005' '10000' '10003' '10001' '10003' '10003' '10003' '10003'\n",
      " '10008' '10003' '10003' '10003' '10003' '10003' '10005' '10005' '10003'\n",
      " '10005' '10003' '10005' '10003' '10013' '10012' '10005' '10003' '10003'\n",
      " '10006' '10003' '10003' '10015' '10008' '10003' '10003' '10006' '10008'\n",
      " '10003' '10003' '10000' '10001' '10003' '10003' '10003' '10003' '10003'\n",
      " '10003' '10003' '10003' '10006' '10003' '10003' '10003' '10003' '10003'\n",
      " '10003' '10003' '10003' '10003' '10003' '10003' '10003' '10003' '10002'\n",
      " '10000' '10013' '10003' '10003' '10003' '10003' '10000' '10003' '10000'\n",
      " '10019' '10003' '10003' '10003' '10003' '10003' '10002' '10006' '10003'\n",
      " '10003' '10005' '10003' '10003' '10003' '10002' '10008' '10006' '10003'\n",
      " '10008' '10003' '10000' '10003' '10003' '10003' '10005' '10003' '10008'\n",
      " '10003' '10006' '10003' '10003' '10003' '10003' '10003' '10003' '10003'\n",
      " '10003' '10003' '10003' '10003' '10005' '10003' '10003' '10000' '10015'\n",
      " '10003' '10003' '10003' '10008' '10003' '10003' '10003' '10003' '10003'\n",
      " '10003' '10000' '10003' '10003' '10003' '10003' '10003' '10003' '10000'\n",
      " '10003' '10005' '10015' '10003' '10003' '10005' '10008' '10005' '10003'\n",
      " '10003' '10003' '10003' '10003' '10003' '10000' '10003' '10003' '10003'\n",
      " '10002' '10005' '10003' '10003' '10013' '10003' '10003' '10000' '10003'\n",
      " '10003' '10003' '10003' '10003' '10000' '10003' '10003' '10003' '10003'\n",
      " '10006' '10000' '10003' '10003' '10003' '10003' '10015' '10003' '10003'\n",
      " '10003' '10003' '10003' '10003' '10008' '10001' '10003' '10003' '10003'\n",
      " '10006' '10015' '10003' '10005' '10002' '10003' '10003' '10003' '10001'\n",
      " '10006' '10003' '10006' '10006' '10003' '10003' '10003' '10016' '10001'\n",
      " '10003' '10003' '10003' '10003' '10003' '10013' '10001' '10003' '10000'\n",
      " '10000' '10005' '10003' '10006' '10005' '10018' '10005' '10008' '10003'\n",
      " '10003' '10008' '10003' '10003' '10003' '10008' '10000' '10003' '10000'\n",
      " '10006' '10005' '10003' '10003' '10005' '10003' '10003' '10003' '10006'\n",
      " '10003' '10003' '10003' '10003' '10003']\n",
      "[[9.72294614e-01 3.37193577e-04 3.27841305e-04 ... 2.04731036e-06\n",
      "  3.64432265e-07 1.02555174e-05]\n",
      " [7.70920805e-02 5.86454736e-02 1.48806321e-02 ... 2.23117946e-03\n",
      "  7.77783257e-02 5.40101425e-03]\n",
      " [9.13152813e-03 1.24912707e-04 1.49420231e-03 ... 4.90319801e-06\n",
      "  1.52610880e-06 2.27238759e-05]\n",
      " ...\n",
      " [4.18578172e-06 1.67975243e-04 7.29745195e-05 ... 1.65503905e-12\n",
      "  5.34819166e-15 8.09090652e-13]\n",
      " [4.56691228e-02 3.78983475e-02 1.91561794e-01 ... 2.32604980e-05\n",
      "  1.26216110e-04 2.87622037e-04]\n",
      " [1.09685612e-03 1.38731892e-04 1.57663362e-03 ... 3.79766387e-06\n",
      "  1.40834294e-06 3.52287030e-06]]\n",
      "0.306\n",
      "0.306\n",
      "0.306\n",
      "0.306\n",
      "0.1446985725695403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       10000       0.59      0.48      0.53        63\n",
      "       10001       0.08      0.03      0.05        30\n",
      "       10002       0.33      0.15      0.21        27\n",
      "       10003       0.22      0.77      0.34        84\n",
      "       10004       0.00      0.00      0.00         5\n",
      "       10005       0.46      0.28      0.34        58\n",
      "       10006       0.33      0.15      0.21        52\n",
      "       10007       0.00      0.00      0.00         2\n",
      "       10008       0.50      0.41      0.45        41\n",
      "       10009       0.00      0.00      0.00         6\n",
      "       10010       0.00      0.00      0.00        14\n",
      "       10011       0.00      0.00      0.00         3\n",
      "       10012       0.00      0.00      0.00         6\n",
      "       10013       0.50      0.18      0.26        28\n",
      "       10014       0.00      0.00      0.00         7\n",
      "       10015       0.55      0.23      0.32        26\n",
      "       10016       0.00      0.00      0.00        14\n",
      "       10017       0.00      0.00      0.00        12\n",
      "       10018       0.33      0.12      0.18         8\n",
      "       10019       0.00      0.00      0.00        14\n",
      "\n",
      "   micro avg       0.31      0.31      0.31       500\n",
      "   macro avg       0.19      0.14      0.14       500\n",
      "weighted avg       0.32      0.31      0.27       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\King\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\King\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(y_test, predicted_y)\n",
    "print(model.predict_proba(X_test))\n",
    "print(accuracy_score(y_test, predicted_y))\n",
    "print(precision_score(y_test, predicted_y, average='micro'))\n",
    "print(recall_score(y_test, predicted_y, average='micro'))\n",
    "print(f1_score(y_test, predicted_y, average='micro'))\n",
    "print(f1_score(y_test, predicted_y, average='macro'))\n",
    "print(classification_report(y_test, predicted_y,output_dict= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
