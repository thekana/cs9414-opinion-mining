{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import metrics, tree\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.feature_selection import chi2, SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.tsv', sep='\\t', quoting=csv.QUOTE_NONE, dtype=str, encoding = 'utf-8',\n",
    "                 header=None, names=[\"instance\", \"text\", \"id\", \"sentiment\", \"is_sarcastic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Functions for text pre-processing \"\"\"\n",
    "\n",
    "\n",
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \"\", sample)\n",
    "\n",
    "\n",
    "def remove_punctuation(sample):\n",
    "    \"\"\"Remove punctuations from a sample string\"\"\"\n",
    "    return re.sub(r'[^\\w\\s\\@\\#]','',sample)\n",
    "\n",
    "def myTokenizer(sample):\n",
    "    \"\"\"Customized tokenizer\"\"\"\n",
    "    new_words = []\n",
    "    words = sample.split(' ')\n",
    "    new_words = [word for word in words if len(word) >= 2 and not word.lower().startswith('au') and not word.lower().startswith('#aus')]\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords_NLTK(sample):\n",
    "    \"\"\"Remove stopwords using NLTK\"\"\"\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    words = [w for w in sample.split(' ') if len(w) >= 2]\n",
    "    filteredText = \"\"\n",
    "    for word in words:\n",
    "        if word not in stopWords:\n",
    "            filteredText = filteredText + word + \" \"\n",
    "    return filteredText.rstrip()\n",
    "\n",
    "def remove_digits(input_text):\n",
    "    return re.sub('\\d+', '', input_text)\n",
    "\n",
    "def porter_stem(sample):\n",
    "    \"\"\"Stemming\"\"\"\n",
    "    words = [w for w in sample.split(' ') if len(w) >= 2]\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_text = \"\"\n",
    "    for word in words:\n",
    "        stemmed_text = stemmed_text + ps.stem(word) + \" \"\n",
    "    return stemmed_text.rstrip()\n",
    "\n",
    "def myPreprocessor(sample):\n",
    "    \"\"\"Customized preprocessor\"\"\"\n",
    "    sample = remove_URL(sample)\n",
    "    sample = remove_punctuation(sample)\n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Data creation \"\"\"\n",
    "text_data = np.array([])\n",
    "# Read tweets\n",
    "for text in df.text:\n",
    "    text_data = np.append(text_data, text)\n",
    "# creating target classes\n",
    "Y = np.array([])\n",
    "for text in df.sentiment:\n",
    "    Y = np.append(Y, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_test_, y_train, y_test = train_test_split(text_data, Y, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#457visa', '#4Corners', '#4corners', '#7News', '#ABC', '#AFPRaids', '#ALP', '#BlackHole', '#Brexit', '#Budget2016', '#CFA', '#CFMEU', '#CSG', '#CSIRO', '#CSIROcuts', '#Canberra', '#ChaFTA', '#ClimateScience', '#Corruption', '#DataRetention', '#Dutton', '#ETS', '#Election2016', '#FederalICAC', '#FederalICACNow', '#Fraudband', '#Gonski', '#GreatBarrierReef', '#Greens', '#Greens16', '#ICAC', '#ICYMI', '#Insiders', '#LNP', '#LNPfail', '#LNPliars', '#LNPs', '#Labor', '#LaborFail', '#LaborLaunch', '#LibLite', '#Liberal', '#Liberals', '#Malcolm', '#Medicare', '#NBN', '#NBNCo', '#NBNGATE', '#NPC', '#Nauru', '#NegativeGearing', '#Parakeelia', '#PutLNPLast', '#RET', '#Refugees', '#SSM', '#SaveMedicare', '#ScoMo', '#SecretETS', '#Spendometer', '#TenNews', '#Turnbull', '#abc730', '#abcnews24', '#asylumseekers', '#betterfuture', '#borderprotection', '#chaos', '#cleanenergy', '#climatechange', '#coal', '#csg', '#education', '#election2016', '#environment', '#faketradie', '#greens16', '#homophobia', '#humanrights', '#inequality', '#insiders', '#leadersdebate', '#lnp', '#medicare', '#nbn', '#negativegearing', '#npc', '#panamapapers', '#peoplesforum', '#putLNPlast', '#pyneocchio', '#qanda', '#qldpol', '#refugees', '#renewables', '#savemedicare', '#springst', '#stopStateTerrorism', '#thedrum', '#turnbull', '10', '100', '12', '15', '1st', '20', '2013', '2016', '2017', '21st', '22', '2nd', '30', '40', '50', '50000', '50b', '60000', '@2GBNews', '@ABCNews', '@ABCNews24', '@AlboMP', '@AustralianLabor', '@Barnaby_Joyce', '@BillShortenMP', '@Bowenchris', '@GChristensenMP', '@Greens', '@GregHuntMP', '@JulieBishopMP', '@LiberalAus', '@Magpie1954nBird', '@MathiasCormann', '@PaulBongiorno', '@PeterDutton_MP', '@PutLaborLast', '@RichardDiNatale', '@ScottMorrisonMP', '@ShaughanA', '@SkyNewsAust', '@TonyAbbottMHR', '@TonyHWindsor', '@TurnbullMalcolm', '@TurnbullMalcolms', '@abcnews', '@billshortenmp', '@cpyne', '@fitzhunter', '@johndory49', '@liberalaus', '@margokingston1', '@smh', '@tanya_plibersek', '@theage', '@vanbadham', 'AAA', 'ABC', 'ABOUT', 'AFP', 'ALL', 'ALP', 'ALPs', 'AND', 'Abbott', 'Abbotts', 'Abortions', 'Action', 'Affordability', 'After', 'All', 'An', 'And', 'Andrews', 'Another', 'As', 'At', 'BREAKING', 'BUT', 'BY', 'Banks', 'Barnaby', 'Barrier', 'Be', 'Big', 'Bill', 'Bird', 'Bishop', 'BizProfits', 'Bloody', 'Bob', 'Border', 'Bowen', 'Brexit', 'Britains', 'Business', 'But', 'CFA', 'CSIRO', 'Cant', 'Cayman', 'Change', 'Chris', 'Claims', 'Climate', 'Co', 'Coalition', 'Come', 'Commission', 'Cormann', 'Corporations', 'DO', 'DONT', 'Di', 'Did', 'Direct', 'Do', 'Doctors', 'Documents', 'Dodgy', 'Does', 'Dont', 'Dr', 'Dutton', 'Duttons', 'EU', 'Economy', 'Edu', 'Education', 'Election', 'Electricty', 'Energy', 'English', 'Enough', 'Even', 'FOR', 'Fact', 'Fair', 'Farage', 'Federal', 'First', 'Flee', 'Fonseca', 'Former', 'Full', 'GDP', 'GET', 'GFC', 'GO', 'GOVT', 'GP', 'GST', 'Gestapo', 'Get', 'Gillard', 'Give', 'Global', 'Good', 'Government', 'Governments', 'Govt', 'GovtRevenue', 'GovtServicesJobs', 'Great', 'Greens', 'Greg', 'Growth', 'Gvt', 'HAS', 'HOusingFAIR', 'He', 'Headspace', 'Health', 'Heres', 'Hey', 'His', 'Hockey', 'Hope', 'Housing', 'How', 'Howard', 'Hunt', 'Hunts', 'ICAC', 'IN', 'IS', 'IT', 'Id', 'If', 'Ilegal', 'Im', 'Immigration', 'In', 'Indonesia', 'Internet', 'Internships', 'Is', 'Islam', 'Islamic', 'Islamist', 'It', 'Its', 'Jobs', 'Joe', 'John', 'Joyce', 'Julie', 'July', 'Just', 'Keating', 'Kelly', 'LAST', 'LIBS', 'LNP', 'LNPs', 'Labor', 'Labors', 'Labrs', 'Leader', 'Learn', 'Lib', 'Liberal', 'Liberals', 'Libs', 'MP', 'MPs', 'MSM', 'MT', 'MUST', 'Major', 'Make', 'Mal', 'Malcolm', 'Manus', 'Marriage', 'Mathias', 'Maybe', 'Medicare', 'Mega', 'Mining', 'Minister', 'More', 'Morrison', 'Mossack', 'Mr', 'Muslims', 'My', 'NBN', 'NOT', 'NSW', 'Natale', 'Nauru', 'Never', 'New', 'News', 'Next', 'No', 'Not', 'Now', 'OR', 'OUT', 'OZ', 'Ok', 'On', 'Once', 'Only', 'Opposition', 'Our', 'Oz', 'PLAN', 'PM', 'PNG', 'Panama', 'Papers', 'Parakeelia', 'Party', 'Partys', 'Pay', 'People', 'Perth', 'Peter', 'Plan', 'Please', 'Pls', 'Policy', 'Post', 'Prime', 'Put', 'Pyne', 'Question', 'RBA', 'REAL', 'RKD', 'RT', 'Real', 'Rebuild', 'Reef', 'Remember', 'Renew', 'Richard', 'Royal', 'SBS', 'SO', 'SSM', 'Same', 'Samesex', 'Says', 'Scott', 'Senate', 'Shame', 'Shocked', 'Shonky', 'Shorten', 'Shortens', 'So', 'South', 'System', 'TAFE', 'TAX', 'THE', 'TO', 'TURNBULL', 'Tampa', 'Tax', 'Taylor', 'That', 'Thats', 'The', 'Their', 'There', 'Theres', 'They', 'Things', 'This', 'Time', 'To', 'Todays', 'Tony', 'Top', 'Treasurer', 'Treasury', 'Trump', 'Trust', 'Turnbull', 'Turnbulls', 'Two', 'UK', 'UKIP', 'US', 'Under', 'VOTE', 'Victoria', 'Vote', 'Voters', 'Voting', 'WA', 'WAS', 'WHY', 'Wages', 'Wait', 'We', 'Weird', 'Well', 'Were', 'Weve', 'What', 'Whats', 'When', 'Where', 'White', 'Who', 'Why', 'Will', 'With', 'Without', 'Work', 'Xrays', 'YOU', 'Yes', 'Yet', 'You', 'Your', 'able', 'about', 'above', 'absolute', 'abuse', 'action', 'actually', 'ad', 'addingValue', 'admits', 'ads', 'afford', 'affordable', 'after', 'again', 'against', 'age', 'agenda', 'agents', 'agile', 'ago', 'aid', 'all', 'alliance', 'allow', 'alone', 'already', 'also', 'always', 'am', 'amp', 'an', 'and', 'announce', 'announcement', 'announces', 'another', 'answer', 'any', 'anyone', 'anything', 'are', 'around', 'as', 'ask', 'asked', 'asking', 'asylum', 'at', 'attack', 'attacks', 'avoid', 'away', 'back', 'backs', 'backward', 'bad', 'balance', 'ban', 'bankers', 'banks', 'barrel', 'based', 'bc', 'be', 'because', 'become', 'been', 'before', 'begun', 'behind', 'being', 'believe', 'believes', 'benefit', 'benefits', 'best', 'better', 'between', 'beyond', 'big', 'biggest', 'bill', 'billing', 'billion', 'billions', 'bit', 'black', 'blaming', 'blood', 'blow', 'boat', 'boats', 'border', 'borders', 'boss', 'both', 'bottom', 'brilliant', 'broadband', 'broke', 'broken', 'budget', 'build', 'building', 'bulk', 'bulkbilling', 'business', 'businesses', 'but', 'buy', 'by', 'call', 'called', 'calling', 'calls', 'campaign', 'can', 'candidate', 'cannot', 'cant', 'carbon', 'care', 'cattle', 'cause', 'centre', 'chance', 'change', 'changes', 'check', 'child', 'childcare', 'children', 'claim', 'class', 'clean', 'clearly', 'climate', 'club', 'coal', 'coalition', 'come', 'comes', 'coming', 'comments', 'commit', 'committed', 'community', 'companies', 'company', 'concentration', 'concerned', 'confident', 'confirmed', 'contact', 'continue', 'continues', 'copper', 'coral', 'core', 'corporate', 'corporations', 'corrupt', 'corruption', 'cost', 'costing', 'costings', 'costs', 'could', 'country', 'crap', 'create', 'created', 'credibility', 'credit', 'criminal', 'crisis', 'criticising', 'cut', 'cuts', 'cutting', 'dairy', 'damaged', 'day', 'days', 'deal', 'debate', 'debt', 'decision', 'defend', 'deficit', 'deficits', 'deliver', 'democracy', 'destroyed', 'destroying', 'detention', 'developers', 'did', 'didnt', 'disastrous', 'discredit', 'dispute', 'distract', 'do', 'doctors', 'documents', 'does', 'doesnt', 'doing', 'dollars', 'donation', 'donations', 'done', 'donor', 'dont', 'doubt', 'down', 'drugs', 'dud', 'due', 'during', 'each', 'early', 'earners', 'economic', 'economics', 'economy', 'education', 'effective', 'eh', 'either', 'elected', 'election', 'electorate', 'electricity', 'end', 'energy', 'ensure', 'equality', 'estate', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'evidence', 'exactly', 'examine', 'expects', 'expensive', 'expert', 'explain', 'explains', 'exports', 'exposed', 'extra', 'extremist', 'eyes', 'fact', 'facts', 'fair', 'fairer', 'fall', 'falling', 'families', 'family', 'far', 'farmers', 'fast', 'faster', 'fault', 'fear', 'feather', 'federal', 'few', 'figure', 'filthy', 'finance', 'financial', 'find', 'firefighters', 'first', 'fiscal', 'fix', 'flows', 'folks', 'for', 'force', 'foreign', 'forget', 'former', 'free', 'freeze', 'from', 'full', 'fully', 'fund', 'funded', 'funding', 'funds', 'furious', 'future', 'gas', 'gay', 'gear', 'gearing', 'get', 'gets', 'getting', 'give', 'given', 'gives', 'giving', 'go', 'going', 'gone', 'good', 'got', 'gov', 'government', 'governments', 'govt', 'govts', 'grandchildren', 'great', 'ground', 'grow', 'growth', 'gt', 'guarantee', 'guns', 'had', 'half', 'halt', 'hands', 'happened', 'hard', 'harsh', 'has', 'hasnt', 'hate', 'have', 'havens', 'havent', 'he', 'head', 'heads', 'health', 'healthcare', 'hear', 'heard', 'heart', 'heath', 'hed', 'held', 'help', 'helping', 'her', 'here', 'hes', 'hey', 'hide', 'hiding', 'high', 'higher', 'him', 'his', 'history', 'hit', 'hole', 'home', 'homeless', 'hope', 'hospitals', 'house', 'housing', 'how', 'hurt', 'idea', 'if', 'illegal', 'illiterate', 'imagination', 'immigration', 'impact', 'implemented', 'important', 'in', 'incentives', 'income', 'increase', 'increasing', 'independent', 'industry', 'information', 'infrastructure', 'innovation', 'innovative', 'insignificance', 'instead', 'integrity', 'interested', 'internet', 'into', 'investigation', 'investment', 'involved', 'iron', 'is', 'isnt', 'issue', 'issues', 'it', 'its', 'job', 'jobs', 'just', 'keep', 'kids', 'killing', 'knew', 'know', 'known', 'knows', 'labor', 'lack', 'last', 'laundering', 'laws', 'lead', 'leader', 'leads', 'leaks', 'least', 'left', 'legal', 'less', 'let', 'lets', 'level', 'lie', 'lied', 'lies', 'like', 'line', 'linked', 'linking', 'links', 'listen', 'listened', 'little', 'live', 'lives', 'lnp', 'local', 'look', 'looking', 'lost', 'lot', 'lots', 'love', 'low', 'lower', 'lowest', 'lying', 'made', 'majority', 'make', 'making', 'manufacturing', 'many', 'marginal', 'market', 'marriage', 'mass', 'mate', 'mates', 'may', 'me', 'mean', 'means', 'measures', 'media', 'medical', 'member', 'members', 'men', 'mental', 'mention', 'message', 'middleincome', 'mill', 'million', 'millions', 'mine', 'minimum', 'mining', 'minister', 'ministers', 'mob', 'mobile', 'money', 'more', 'most', 'much', 'multinationals', 'must', 'my', 'named', 'nation', 'national', 'need', 'needed', 'needs', 'neg', 'negative', 'negatively', 'never', 'new', 'news', 'next', 'no', 'not', 'nothing', 'now', 'of', 'off', 'offer', 'office', 'offices', 'offshore', 'old', 'on', 'once', 'one', 'only', 'open', 'or', 'orders', 'other', 'otherwise', 'our', 'out', 'over', 'overseas', 'own', 'owners', 'paid', 'parents', 'parliament', 'part', 'parties', 'party', 'pass', 'passed', 'past', 'patients', 'pay', 'paying', 'payment', 'payments', 'pays', 'penalty', 'pension', 'pensions', 'people', 'per', 'perfect', 'persecution', 'personal', 'phase', 'plan', 'plane', 'plans', 'please', 'plebiscite', 'pledge', 'pledges', 'point', 'police', 'policies', 'policy', 'political', 'politician', 'poll', 'poor', 'positive', 'power', 'ppl', 'price', 'prices', 'private', 'privatisation', 'privatise', 'privatised', 'problem', 'profit', 'profits', 'program', 'promise', 'promises', 'promising', 'property', 'prosperity', 'protect', 'protected', 'protection', 'protest', 'proud', 'proved', 'proves', 'provide', 'public', 'put', 'questions', 'racism', 'radical', 'radio', 'raids', 'raise', 'raising', 'rate', 'rates', 'rather', 'rating', 're', 'reading', 'real', 'reality', 'really', 'reason', 'rebate', 'recession', 'record', 'reduce', 'reduced', 'reducing', 'reform', 'reforms', 'refugee', 'refugees', 'refuses', 'religion', 'remember', 'renewable', 'report', 'respect', 'response', 'responsibility', 'responsible', 'restore', 'return', 'revenue', 'reverse', 'rhetoric', 'rich', 'right', 'rights', 'rise', 'rises', 'risk', 'roads', 'roll', 'rort', 'run', 'running', 'runs', 'sack', 'sacked', 'safe', 'said', 'same', 'save', 'saved', 'say', 'saying', 'says', 'scandal', 'scare', 'scared', 'schools', 'screw', 'seat', 'second', 'secret', 'sector', 'security', 'see', 'seeker', 'seekers', 'sell', 'selling', 'service', 'services', 'set', 'share', 'she', 'shocking', 'shooting', 'shore', 'short', 'should', 'shouldnt', 'show', 'shows', 'shut', 'silent', 'since', 'single', 'sitting', 'slashed', 'slashing', 'slow', 'small', 'smart', 'so', 'social', 'society', 'sole', 'solution', 'some', 'something', 'soon', 'spend', 'spending', 'spent', 'stability', 'stage', 'stand', 'started', 'state', 'states', 'still', 'stop', 'stopped', 'stories', 'story', 'strategy', 'street', 'strong', 'strongly', 'stupid', 'submarines', 'subsidies', 'suicide', 'super', 'superannuation', 'support', 'supporting', 'sure', 'surplus', 'surprise', 'system', 'take', 'taking', 'talk', 'talking', 'targets', 'tax', 'taxation', 'taxes', 'taxpayer', 'taxpayers', 'team', 'tell', 'term', 'terror', 'terrorist', 'terrorists', 'tests', 'than', 'thanks', 'that', 'thats', 'the', 'their', 'them', 'themselves', 'then', 'there', 'theres', 'these', 'they', 'theyll', 'theyre', 'thing', 'things', 'think', 'thinks', 'this', 'those', 'though', 'thought', 'thousands', 'threat', 'threaten', 'three', 'throwing', 'till', 'time', 'times', 'to', 'today', 'todays', 'told', 'too', 'took', 'total', 'trade', 'transition', 'treasurer', 'tried', 'true', 'trust', 'trustPM', 'trusted', 'try', 'turnbull', 'turning', 'two', 'under', 'unemployed', 'unemployment', 'unfreeze', 'unions', 'unless', 'until', 'up', 'urge', 'us', 'use', 'used', 'using', 'usual', 'value', 'very', 'via', 'visas', 'visit', 'volunteers', 'vote', 'voted', 'voters', 'votes', 'voting', 'vulnerable', 'wa', 'wages', 'waiting', 'want', 'wants', 'war', 'warnings', 'was', 'wasnt', 'waste', 'wasted', 'water', 'way', 'we', 'wealth', 'wealthy', 'week', 'weeks', 'welfare', 'well', 'were', 'what', 'whats', 'when', 'where', 'which', 'while', 'who', 'whole', 'why', 'will', 'win', 'wins', 'with', 'within', 'without', 'wk', 'women', 'won', 'wonder', 'wont', 'word', 'words', 'work', 'worked', 'workers', 'working', 'world', 'worried', 'worse', 'worst', 'worth', 'would', 'wouldnt', 'wrong', 'xenophobia', 'ya', 'yeah', 'year', 'years', 'yet', 'you', 'young', 'your', 'youre', 'yours', 'youth', 'youve', 'yr', 'yrs', 'zero']\n"
     ]
    }
   ],
   "source": [
    "count = CountVectorizer(preprocessor=myPreprocessor, tokenizer = myTokenizer, max_features=1400, ngram_range=(1,1), min_df = 1, max_df = 0.4)\n",
    "X_train = count.fit_transform(X_train_).toarray()\n",
    "X_test = count.transform(X_test_).toarray()\n",
    "print(count.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha = 1.0)\n",
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84       335\n",
      "     neutral       0.59      0.54      0.56       125\n",
      "    positive       0.75      0.23      0.35        40\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       500\n",
      "   macro avg       0.71      0.55      0.58       500\n",
      "weighted avg       0.74      0.75      0.73       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92       959\n",
      "     neutral       0.83      0.81      0.82       428\n",
      "    positive       0.93      0.67      0.78       113\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1500\n",
      "   macro avg       0.88      0.81      0.84      1500\n",
      "weighted avg       0.88      0.88      0.88      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76309227 0.72568579 0.73566085 0.74185464 0.74120603]\n",
      "F1 micro Accuracy: 0.74 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(CountVectorizer(preprocessor=myPreprocessor, tokenizer = myTokenizer, max_features=1400, ngram_range=(1,1), min_df = 1, max_df = 0.4), MultinomialNB(alpha =  1.0))\n",
    "scores = cross_val_score(clf,text_data,Y,cv=5,scoring = 'f1_micro')\n",
    "print(scores)\n",
    "print(\"F1 micro Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model_new.predict(text_data[:1500])\n",
    "# print(classification_report(Y[:1500], y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
