{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn import metrics, tree\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.tsv', sep='\\t', quoting=csv.QUOTE_NONE, dtype=str,\n",
    "                 header=None, names=[\"instance\", \"text\", \"id\", \"sentiment\", \"is_sarcastic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = np.array([])\n",
    "# Read tweets\n",
    "for text in df.text:\n",
    "    text_data = np.append(text_data, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Functions for text pre-processing \"\"\"\n",
    "\n",
    "\n",
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \" \", sample)\n",
    "\n",
    "\n",
    "def remove_punctuation(sample):\n",
    "    \"\"\"Remove punctuations from a sample string\"\"\"\n",
    "    punctuations = r'''$!\"&'()*+,-./:;<=>?[\\]^`{|}~'''\n",
    "    no_punct = \"\"\n",
    "    for char in sample:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "def myTokenizer(sample):\n",
    "    \"\"\"Customized tokenizer\"\"\"\n",
    "    ################################## 1. Remove numbers\n",
    "    ################################## 2. Remove auspoll thingy\n",
    "    ################################## 3. Remove starts with au\n",
    "    new_words = []\n",
    "    words = sample.split(' ')\n",
    "    new_words = [word for word in words if len(word) >= 2 and not word.isdigit() and not word.startswith('#aus') and not word.startswith('au')]\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords_NLTK(sample):\n",
    "    \"\"\"Remove stopwords using NLTK\"\"\"\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    words = myTokenizer(sample)\n",
    "    filteredText = \"\"\n",
    "    for word in words:\n",
    "        if word not in stopWords:\n",
    "            filteredText = filteredText + word + \" \"\n",
    "    return filteredText.rstrip()\n",
    "\n",
    "\n",
    "def porter_stem(sample):\n",
    "    \"\"\"Stemming\"\"\"\n",
    "    words = myTokenizer(sample)\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_text = \"\"\n",
    "    for word in words:\n",
    "        stemmed_text = stemmed_text + ps.stem(word) + \" \"\n",
    "    return stemmed_text.rstrip()\n",
    "\n",
    "\n",
    "def myPreprocessor(sample):\n",
    "    \"\"\"Customized preprocessor\"\"\"\n",
    "    sample = remove_URL(sample)\n",
    "    sample = sample.lower()\n",
    "    sample = remove_stopwords_NLTK(sample)\n",
    "    sample = remove_punctuation(sample)\n",
    "    sample = porter_stem(sample)\n",
    "    return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#4corner', '#7new', '#abc730', '#abcnews24', '#afpraid', '#agchatoz', '#alp', '#asylumseek', '#brexit', '#budget2016', '#cfa', '#cfmeu', '#chafta', '#climat', '#climatechang', '#coal', '#corrupt', '#csg', '#csiro', '#csirocut', '#dutton', '#educ', '#election2016', '#environ', '#et', '#faketradi', '#fraudband', '#gonski', '#green', '#greens16', '#humanright', '#icac', '#inequ', '#insid', '#labor', '#laborlaunch', '#latelin', '#leadersdeb', '#liber', '#lnp', '#lnpfail', '#malcolm', '#marriageequ', '#medicar', '#nauru', '#nbn', '#nbnco', '#nbngate', '#negativegear', '#npc', '#panamapap', '#parakeelia', '#peoplesforum', '#putlnplast', '#qanda', '#qldpol', '#refuge', '#renew', '#savemedicar', '#scomo', '#spendomet', '#springst', '#ssm', '#stopstateterror', '#tennew', '#thedrum', '#turnbul', '1st', '2nd', '50%', '50b', '50bn', '@2gbnew', '@abcnew', '@abcnews24', '@albomp', '@australianlabor', '@barnaby_joyc', '@billshortenmp', '@bowenchri', '@cpyne', '@green', '@greghuntmp', '@johndory49', '@juliebishopmp', '@liberalau', '@mathiascormann', '@peterdutton_mp', '@richarddinatal', '@scottmorrisonmp', '@skynewsaust', '@smh', '@tanya_plibersek', '@theag', '@tonyabbottmhr', '@tonyhwindsor', '@turnbullmalcolm', 'aaa', 'abbott', 'abc', 'abl', 'absolut', 'abus', 'act', 'action', 'actual', 'ad', 'admit', 'adopt', 'afford', 'afp', 'again', 'age', 'agenda', 'agent', 'ago', 'agre', 'aid', 'all', 'alleg', 'allow', 'alon', 'alp', 'alreadi', 'also', 'alway', 'amp', 'analysi', 'andrew', 'announc', 'anoth', 'answer', 'anyon', 'anyth', 'approv', 'around', 'ask', 'asylum', 'attack', 'avoid', 'away', 'back', 'ban', 'bank', 'barnabi', 'barrier', 'becom', 'behind', 'believ', 'benefit', 'best', 'better', 'big', 'biggest', 'bill', 'billion', 'bishop', 'black', 'blame', 'bloodi', 'blow', 'boat', 'border', 'bottom', 'bowen', 'break', 'brexit', 'britain', 'broadband', 'broken', 'budget', 'build', 'bulk', 'busi', 'buy', 'call', 'camp', 'campaign', 'candid', 'cannot', 'cant', 'carbon', 'care', 'cash', 'cattl', 'caus', 'cayman', 'centr', 'ceo', 'cfa', 'chang', 'child', 'childcar', 'children', 'choic', 'chri', 'claim', 'class', 'clean', 'climat', 'co', 'coal', 'coalit', 'come', 'comment', 'commiss', 'commit', 'commun', 'compani', 'concern', 'confid', 'confirm', 'contact', 'continu', 'copper', 'cormann', 'corp', 'corpor', 'corrupt', 'cost', 'could', 'council', 'countri', 'coz', 'creat', 'credibl', 'credit', 'crimin', 'criticis', 'csiro', 'cut', 'dairi', 'day', 'deal', 'debat', 'debt', 'decid', 'decis', 'declar', 'defend', 'deficit', 'deliv', 'democraci', 'deni', 'dept', 'deserv', 'desper', 'destroy', 'detail', 'detent', 'develop', 'di', 'die', 'differ', 'digit', 'direct', 'disgrac', 'distract', 'doctor', 'document', 'dodgi', 'dollar', 'donat', 'done', 'donor', 'dud', 'due', 'dutton', 'earli', 'earner', 'econom', 'economi', 'ed', 'educ', 'effect', 'either', 'elect', 'elector', 'electr', 'end', 'energi', 'english', 'ensur', 'equal', 'etc', 'eu', 'even', 'ever', 'everi', 'everyon', 'everyth', 'evid', 'exactli', 'expect', 'expens', 'expert', 'explain', 'export', 'expos', 'extra', 'eye', 'face', 'fact', 'fail', 'fair', 'fall', 'famili', 'far', 'farmer', 'fault', 'fear', 'feder', 'fee', 'feel', 'fight', 'final', 'financ', 'find', 'first', 'fix', 'folk', 'follow', 'fool', 'forc', 'foreign', 'forget', 'former', 'free', 'freez', 'fta', 'full', 'fulli', 'fund', 'funnel', 'futur', 'gay', 'gdp', 'gear', 'get', 'gfc', 'give', 'given', 'go', 'goe', 'good', 'got', 'gov', 'govern', 'govt', 'gp', 'great', 'green', 'greg', 'grow', 'growth', 'gst', 'guarante', 'half', 'happen', 'hard', 'hate', 'haven', 'he', 'head', 'health', 'hear', 'held', 'help', 'here', 'hey', 'hide', 'high', 'higher', 'histori', 'hit', 'hole', 'home', 'hope', 'hospit', 'hous', 'hunt', 'hurt', 'idea', 'ignor', 'ill', 'illeg', 'illiter', 'im', 'imagin', 'immigr', 'impact', 'import', 'in', 'increas', 'independ', 'indonesia', 'industri', 'inform', 'innov', 'integr', 'interest', 'internet', 'invest', 'investig', 'is', 'islam', 'islamist', 'island', 'issu', 'it', 'job', 'joke', 'joyc', 'juli', 'keep', 'kelli', 'kid', 'kill', 'knew', 'know', 'known', 'labor', 'labor’', 'lack', 'last', 'launder', 'law', 'lead', 'leader', 'leak', 'learn', 'left', 'legal', 'less', 'let', 'liar', 'lib', 'liber', 'liberals’', 'lie', 'like', 'line', 'link', 'listen', 'littl', 'live', 'lnp', 'loan', 'local', 'lock', 'lol', 'long', 'look', 'lose', 'lost', 'lot', 'love', 'low', 'lower', 'mad', 'made', 'mafia', 'major', 'make', 'mal', 'malcolm', 'man', 'manag', 'mani', 'manu', 'manufactur', 'margin', 'mark', 'market', 'marriag', 'mate', 'mathia', 'may', 'me', 'mean', 'measur', 'media', 'medic', 'medicar', 'member', 'mental', 'mention', 'migrant', 'million', 'mine', 'minist', 'money', 'morn', 'morrison', 'mossack', 'mp', 'mr', 'msm', 'mt', 'much', 'multin', 'muslim', 'must', 'name', 'natal', 'nation', 'nauru', 'nbn', 'need', 'neg', 'never', 'new', 'news', 'next', 'no', 'not', 'noth', 'now', 'nsw', 'obsess', 'off', 'offer', 'offic', 'offici', 'offshor', 'ok', 'old', 'on', 'one', 'open', 'opposit', 'order', 'out', 'oversea', 'owner', 'oz', 'paid', 'panama', 'paper', 'parakeelia', 'parent', 'part', 'parti', 'pass', 'past', 'patient', 'pay', 'payment', 'penalti', 'pension', 'peopl', 'per', 'person', 'peter', 'plan', 'pleas', 'plebiscit', 'pledg', 'pm', 'point', 'polic', 'polici', 'polit', 'politician', 'poll', 'poor', 'posit', 'power', 'ppl', 'price', 'prime', 'privat', 'privatis', 'problem', 'profit', 'program', 'promis', 'promot', 'properti', 'protect', 'prove', 'provid', 'public', 'put', 'pyne', 'question', 'quit', 'racism', 'raid', 'rais', 'rate', 'rba', 're', 'read', 'readi', 'real', 'realiti', 'realli', 'reason', 'rebat', 'record', 'reduc', 'reef', 'reform', 'refuge', 'refus', 'releas', 'rememb', 'remov', 'renew', 'report', 'research', 'respect', 'respons', 'return', 'reveal', 'revers', 'rich', 'right', 'rise', 'risk', 'road', 'roll', 'rort', 'royal', 'run', 'sa', 'sack', 'safe', 'said', 'samesex', 'save', 'say', 'sb', 'scandal', 'scare', 'school', 'scott', 'scrap', 'screw', 'sea', 'seat', 'second', 'secret', 'sector', 'secur', 'see', 'seek', 'seeker', 'seem', 'sell', 'seriou', 'servic', 'set', 'shame', 'shock', 'shorten', 'show', 'sign', 'sinc', 'singl', 'slash', 'slow', 'small', 'so', 'social', 'societi', 'solut', 'someth', 'soon', 'sort', 'spend', 'spent', 'ssm', 'stabil', 'stand', 'start', 'state', 'statement', 'still', 'stop', 'stori', 'strategi', 'strong', 'student', 'stuff', 'stupid', 'submarin', 'subsidi', 'suicid', 'super', 'superannu', 'support', 'sure', 'surplu', 'system', 'tafe', 'take', 'talk', 'target', 'tax', 'taxat', 'taxpay', 'team', 'tell', 'ten', 'term', 'terror', 'terrorist', 'test', 'thank', 'that', 'the', 'them', 'there', 'theyll', 'thi', 'thing', 'think', 'though', 'till', 'time', 'today', 'told', 'toni', 'took', 'top', 'total', 'trade', 'transfer', 'transit', 'treasur', 'tri', 'true', 'trump', 'trust', 'truth', 'turn', 'turnbul', 'turnbull’', 'two', 'uk', 'unemploy', 'union', 'urg', 'us', 'use', 'valu', 'via', 'victoria', 'view', 'visa', 'visit', 'volunt', 'vote', 'voter', 'wa', 'wage', 'wait', 'want', 'war', 'warn', 'wast', 'watch', 'water', 'way', 'we', 'wealthi', 'week', 'welfar', 'well', 'were', 'weve', 'what', 'whether', 'who', 'win', 'within', 'without', 'women', 'wonder', 'wont', 'word', 'work', 'worker', 'world', 'wors', 'worst', 'worth', 'would', 'wrong', 'xenophobia', 'ye', 'yeah', 'year', 'yet', 'you', 'your', 'yr', 'zero']\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "# try to use sklearn stop_words later\n",
    "count = CountVectorizer(preprocessor=myPreprocessor, tokenizer=myTokenizer, max_features=800)\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "print(count.get_feature_names())\n",
    "size = len(count.vocabulary_)\n",
    "print(len(count.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bag_of_words.toarray()\n",
    "# creating target classes\n",
    "Y = np.array([])\n",
    "for text in df.id:\n",
    "    Y = np.append(Y, text)\n",
    "# First 1500 for training set, last 500 for test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       10000       0.58      0.66      0.62        56\n",
      "       10001       0.35      0.25      0.29        36\n",
      "       10002       0.56      0.45      0.50        31\n",
      "       10003       0.32      0.53      0.40        87\n",
      "       10004       0.00      0.00      0.00         2\n",
      "       10005       0.58      0.62      0.60        52\n",
      "       10006       0.43      0.36      0.40        44\n",
      "       10007       0.00      0.00      0.00         2\n",
      "       10008       0.61      0.72      0.66        46\n",
      "       10009       0.00      0.00      0.00         4\n",
      "       10010       0.27      0.27      0.27        11\n",
      "       10011       0.00      0.00      0.00         7\n",
      "       10012       0.00      0.00      0.00         4\n",
      "       10013       0.62      0.43      0.51        37\n",
      "       10014       0.00      0.00      0.00         6\n",
      "       10015       0.50      0.62      0.56        24\n",
      "       10016       0.25      0.14      0.18        14\n",
      "       10017       0.00      0.00      0.00        12\n",
      "       10018       0.50      0.30      0.37        10\n",
      "       10019       0.50      0.20      0.29        15\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       500\n",
      "   macro avg       0.30      0.28      0.28       500\n",
      "weighted avg       0.44      0.46      0.44       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Doodey\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       10000       0.83      0.84      0.83       188\n",
      "       10001       0.77      0.64      0.70       104\n",
      "       10002       0.70      0.81      0.75        99\n",
      "       10003       0.65      0.76      0.70       271\n",
      "       10004       1.00      0.40      0.57        15\n",
      "       10005       0.72      0.79      0.75       142\n",
      "       10006       0.79      0.81      0.80       145\n",
      "       10007       0.00      0.00      0.00         5\n",
      "       10008       0.79      0.84      0.81       117\n",
      "       10009       0.78      0.58      0.67        12\n",
      "       10010       0.58      0.62      0.60        45\n",
      "       10011       0.00      0.00      0.00         6\n",
      "       10012       0.73      0.52      0.61        21\n",
      "       10013       0.81      0.88      0.84        67\n",
      "       10014       1.00      0.30      0.47        23\n",
      "       10015       0.80      0.97      0.88        95\n",
      "       10016       0.80      0.44      0.57        45\n",
      "       10017       0.85      0.49      0.62        35\n",
      "       10018       0.72      0.64      0.68        28\n",
      "       10019       0.94      0.46      0.62        37\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1500\n",
      "   macro avg       0.71      0.59      0.62      1500\n",
      "weighted avg       0.75      0.75      0.74      1500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Doodey\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
