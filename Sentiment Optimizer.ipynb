{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from time import time\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import collections\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.tsv', sep='\\t', quoting=csv.QUOTE_NONE, dtype=str, encoding = 'utf-8',\n",
    "                 header=None, names=[\"instance\", \"text\", \"id\", \"sentiment\", \"is_sarcastic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Functions for text pre-processing \"\"\"\n",
    "\n",
    "\n",
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \" \", sample)\n",
    "\n",
    "\n",
    "def remove_punctuation(sample):\n",
    "    \"\"\"Remove punctuations from a sample string\"\"\"\n",
    "    return re.sub(r'[^\\w\\s\\&\\#\\@\\$\\%\\_]','',sample)\n",
    "\n",
    "def myTokenizer(sample):\n",
    "    \"\"\"Customized tokenizer\"\"\"\n",
    "    new_words = []\n",
    "    words = sample.split(' ')\n",
    "    new_words = [word for word in words if len(word) >= 2 and not word.startswith('au') and not word.startswith('#aus')]\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords_NLTK(sample):\n",
    "    \"\"\"Remove stopwords using NLTK\"\"\"\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    words = [w for w in sample.split(' ') if len(w) >= 2]\n",
    "    filteredText = \"\"\n",
    "    for word in words:\n",
    "        if word not in stopWords:\n",
    "            filteredText = filteredText + word + \" \"\n",
    "    return filteredText.rstrip()\n",
    "\n",
    "def remove_digits(input_text):\n",
    "    return re.sub('\\d+', '', input_text)\n",
    "\n",
    "def porter_stem(sample):\n",
    "    \"\"\"Stemming\"\"\"\n",
    "    words = [w for w in sample.split(' ') if len(w) >= 2]\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_text = \"\"\n",
    "    for word in words:\n",
    "        stemmed_text = stemmed_text + ps.stem(word) + \" \"\n",
    "    return stemmed_text.rstrip()\n",
    "\n",
    "def myPreprocessor(sample):\n",
    "    \"\"\"Customized preprocessor\"\"\"\n",
    "    sample = remove_URL(sample)\n",
    "    # sample = sample.lower()\n",
    "    sample = remove_punctuation(sample)\n",
    "    # sample = remove_digits(sample)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Data creation \"\"\"\n",
    "text_data = np.array([])\n",
    "# Read tweets\n",
    "for text in df.text:\n",
    "    text_data = np.append(text_data, text)\n",
    "# creating target classes\n",
    "Y = np.array([])\n",
    "for text in df.sentiment:\n",
    "    Y = np.append(Y, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text_data, Y, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html\n",
    "def grid_vect(clf, parameters_clf, X_train, X_test, parameters_text=None, vect=None):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect)\n",
    "        , ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    # Join the parameters dictionaries together\n",
    "    parameters = dict()\n",
    "    if parameters_text:\n",
    "        parameters.update(parameters_text)\n",
    "    parameters.update(parameters_clf)\n",
    "\n",
    "    # Make sure you have scikit-learn version 0.19 or higher to use multiple scoring metrics\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, cv=5, scoring='f1_micro')\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best CV score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test))\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report Test Data\")\n",
    "    print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "                        \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid settings for the vectorizers (Count and TFIDF)\n",
    "parameters_vect = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__min_df': (1,2,3,4,5),\n",
    "    'vect__max_features': (200,400,600,700,800,1000,1200,1400),\n",
    "    'vect__max_df': (0.2, 0.4, 0.6, 0.8 ,1.0)\n",
    "#     'vect__preprocessor':(None, myPreprocessor),\n",
    "#     'vect__tokenizer':(None, myTokenizer)\n",
    "}\n",
    "\n",
    "\n",
    "# Parameter grid settings for MultinomialNB\n",
    "parameters_mnb = {\n",
    "    'clf__alpha': (0.25, 0.5, 0.6 ,0.75, 1.0)\n",
    "}\n",
    "\n",
    "parameters_rf = {\n",
    "    'clf__bootstrap': [True, False],\n",
    "    'clf__max_depth': [60, 70, 80, 90, 100, None],\n",
    "    'clf__max_features': ['auto', 'sqrt'],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__n_estimators': [600, 800, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.6, 0.75, 1.0),\n",
      " 'vect__max_df': (0.2, 0.4, 0.6, 0.8, 1.0),\n",
      " 'vect__max_features': (200, 400, 600, 700, 800, 1000, 1200, 1400),\n",
      " 'vect__min_df': (1, 2, 3, 4, 5),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1528 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2428 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3528 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 4828 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6328 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8028 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9928 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 158.473s\n",
      "\n",
      "Best CV score: 0.739\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1.0\n",
      "\tvect__max_df: 0.4\n",
      "\tvect__max_features: 1400\n",
      "\tvect__min_df: 1\n",
      "\tvect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.748\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84       335\n",
      "     neutral       0.59      0.54      0.57       125\n",
      "    positive       0.73      0.20      0.31        40\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       500\n",
      "   macro avg       0.71      0.54      0.57       500\n",
      "weighted avg       0.74      0.75      0.73       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocessor=myPreprocessor, tokenizer= myTokenizer\n",
    "best_mnb_countvect = grid_vect(MultinomialNB(), parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=CountVectorizer(preprocessor=myPreprocessor, tokenizer= myTokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "{'clf__bootstrap': [True, False],\n",
      " 'clf__max_depth': [60, 70, 80, 90, 100, None],\n",
      " 'clf__max_features': ['auto', 'sqrt'],\n",
      " 'clf__min_samples_leaf': [1, 2, 4],\n",
      " 'clf__min_samples_split': [2, 5, 10],\n",
      " 'clf__n_estimators': [600, 800, 1000]}\n",
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3240 out of 3240 | elapsed: 14.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 845.660s\n",
      "\n",
      "Best CV score: 0.754\n",
      "Best parameters set:\n",
      "\tclf__bootstrap: True\n",
      "\tclf__max_depth: 90\n",
      "\tclf__max_features: 'sqrt'\n",
      "\tclf__min_samples_leaf: 1\n",
      "\tclf__min_samples_split: 2\n",
      "\tclf__n_estimators: 800\n",
      "Test score with best_estimator_: 0.746\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.90      0.84       335\n",
      "     neutral       0.59      0.49      0.54       125\n",
      "    positive       0.91      0.25      0.39        40\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       500\n",
      "   macro avg       0.76      0.55      0.59       500\n",
      "weighted avg       0.74      0.75      0.73       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "best_random = grid_vect(RandomForestClassifier(), parameters_rf, X_train, X_test, parameters_text=None, vect=CountVectorizer(preprocessor=myPreprocessor, tokenizer= myTokenizer, max_features=700, ngram_range=(1, 1), min_df=4, max_df=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
